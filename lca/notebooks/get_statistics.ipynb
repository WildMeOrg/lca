{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from preprocess import preprocess_data\n",
    "from embeddings import Embeddings\n",
    "from curate_using_LCA import curate_using_LCA, generate_wgtr_calibration_ground_truth\n",
    "from tools import load_pickle, print_intersect_stats, get_config\n",
    "from cluster_validator import ClusterValidator\n",
    "import ga_driver\n",
    "from init_logger import init_logger\n",
    "import argparse\n",
    "from sklearn.metrics import pairwise_distances_chunked\n",
    "\n",
    "\n",
    "def get_score_from_cosine_distance(cosine_dist):\n",
    "    \"\"\"Convert cosine distance to a score.\"\"\"\n",
    "    return 1 - cosine_dist * 0.5\n",
    "\n",
    "\n",
    "def get_topk_acc(labels_q, labels_db, dists, topk):\n",
    "    \"\"\"Compute top-k accuracy for label queries.\"\"\"\n",
    "    return sum(get_topk_hits(labels_q, labels_db, dists, topk)) / len(labels_q)\n",
    "\n",
    "\n",
    "def get_topk_hits(labels_q, labels_db, dists, topk):\n",
    "    \"\"\"Return whether the correct label is in the top-k closest predictions.\"\"\"\n",
    "    indices = np.argsort(dists, axis=1)\n",
    "    top_labels = np.array(labels_db)[indices[:, :topk]]\n",
    "    hits = (top_labels.T == labels_q).T\n",
    "    return np.sum(hits[:, :topk+1], axis=1) > 0\n",
    "\n",
    "\n",
    "def get_top_ks(q_pids, distmat, ks=[1, 3, 5, 10]):\n",
    "    \"\"\"Calculate top-k accuracies for the given distance matrix.\"\"\"\n",
    "    return [(k, get_topk_acc(q_pids, q_pids, distmat, k)) for k in ks]\n",
    "\n",
    "\n",
    "def calculate_distances(embeddings, ids, uuids, reduce_func):\n",
    "    \"\"\"Calculate pairwise distances and apply a reduction function.\"\"\"\n",
    "    print(f\"Calculating distances for {len(embeddings)} embeddings and {len(ids)} IDs...\")\n",
    "\n",
    "    chunks = pairwise_distances_chunked(\n",
    "        embeddings,\n",
    "        metric='cosine',\n",
    "        reduce_func=reduce_func,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    return np.concatenate(list(chunks), axis=0)\n",
    "\n",
    "\n",
    "def prepare_reduce_func():\n",
    "    \"\"\"Prepare the distance reduction function that applies cosine distance transformation.\"\"\"\n",
    "    def reduce_func(distmat, start):\n",
    "        distmat = 1 - get_score_from_cosine_distance(distmat)\n",
    "        np.fill_diagonal(distmat, np.inf)\n",
    "        return distmat\n",
    "    return reduce_func\n",
    "\n",
    "\n",
    "def get_stats(df, filter_key, embeddings):\n",
    "    \"\"\"Compute statistics based on distance matrix and top-k accuracy.\"\"\"\n",
    "    uuids = {i: row['uuid_x'] for i, row in df.iterrows()}\n",
    "    ids = list(uuids.keys())\n",
    "\n",
    "    reduce_func = prepare_reduce_func()\n",
    "\n",
    "    # Calculate distance matrix\n",
    "    distmat = calculate_distances(embeddings, ids, uuids, reduce_func)\n",
    "\n",
    "    # Map labels and compute top-k accuracies\n",
    "    labels = [df.loc[df['uuid_x'] == uuids[id], filter_key].values[0] for id in ids]\n",
    "    return get_top_ks(labels, distmat, ks=[1, 3, 5, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_keys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5027bc359abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mname_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'name_keys' is not defined"
     ]
    }
   ],
   "source": [
    "name_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO   2024-09-19 12:24:43,519 [          tools.py: 14] Loading config from path: configs/config_zebra.yaml\n",
      "INFO   2024-09-19 12:24:43,519 [          tools.py: 14] Loading config from path: configs/config_zebra.yaml\n",
      "INFO   2024-09-19 12:24:43,519 [          tools.py: 14] Loading config from path: configs/config_zebra.yaml\n",
      "INFO   2024-09-19 12:24:43,519 [          tools.py: 14] Loading config from path: configs/config_zebra.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT\n",
      "Merging on image uuid\n",
      "** Loaded /ekaterina/work/data/zebra/annotations/zebra.json **\n",
      "      Found 3856 annotations\n",
      "      3846 annotations remain after filtering by given uuids\n",
      "      3846 annotations remain after filtering by viewpoint list ['right', 'left']\n",
      "      3846 annotations remain after filtering by min 2 per name__viewpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO   2024-09-19 12:24:44,670 [          tools.py:177] ** Dataset statistcs **\n",
      "INFO   2024-09-19 12:24:44,670 [          tools.py:177] ** Dataset statistcs **\n",
      "INFO   2024-09-19 12:24:44,670 [          tools.py:177] ** Dataset statistcs **\n",
      "INFO   2024-09-19 12:24:44,670 [          tools.py:177] ** Dataset statistcs **\n",
      "INFO   2024-09-19 12:24:44,674 [          tools.py:178]  - Counts: \n",
      "INFO   2024-09-19 12:24:44,674 [          tools.py:178]  - Counts: \n",
      "INFO   2024-09-19 12:24:44,674 [          tools.py:178]  - Counts: \n",
      "INFO   2024-09-19 12:24:44,674 [          tools.py:178]  - Counts: \n",
      "INFO   2024-09-19 12:24:44,681 [          tools.py:182]  ---- number of individuals: 413\n",
      "INFO   2024-09-19 12:24:44,681 [          tools.py:182]  ---- number of individuals: 413\n",
      "INFO   2024-09-19 12:24:44,681 [          tools.py:182]  ---- number of individuals: 413\n",
      "INFO   2024-09-19 12:24:44,681 [          tools.py:182]  ---- number of individuals: 413\n",
      "INFO   2024-09-19 12:24:44,685 [          tools.py:183]  ---- number of annotations: 3846\n",
      "INFO   2024-09-19 12:24:44,685 [          tools.py:183]  ---- number of annotations: 3846\n",
      "INFO   2024-09-19 12:24:44,685 [          tools.py:183]  ---- number of annotations: 3846\n",
      "INFO   2024-09-19 12:24:44,685 [          tools.py:183]  ---- number of annotations: 3846\n",
      "INFO   2024-09-19 12:24:44,688 [          tools.py:185]  ---- average number of annotations per individual: 9.31\n",
      "INFO   2024-09-19 12:24:44,688 [          tools.py:185]  ---- average number of annotations per individual: 9.31\n",
      "INFO   2024-09-19 12:24:44,688 [          tools.py:185]  ---- average number of annotations per individual: 9.31\n",
      "INFO   2024-09-19 12:24:44,688 [          tools.py:185]  ---- average number of annotations per individual: 9.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3846 annotations remain after filtering by max 100 per name__viewpoint\n",
      "      3846 annotations remain after filtering by the provided embeddings\n",
      "      3846 embeddings remain after filtering by the provided annotations\n",
      "Calculating distances for 3846 embeddings and 3846 IDs...\n",
      "Statistics: top-1: 78.94%, top-3: 89.86%, top-5: 91.89%, top-10: 92.80%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init_logger()\n",
    "config = get_config(\"configs/config_zebra.yaml\")\n",
    "# run(config)\n",
    "\"\"\"Main pipeline function to process embeddings and calculate statistics.\"\"\"\n",
    "data_params = config['data']\n",
    "\n",
    "# Load embeddings and UUIDs\n",
    "embeddings, uuids = load_pickle(data_params['embedding_file'])\n",
    "\n",
    "# Preprocess data\n",
    "name_keys = data_params['name_keys']\n",
    "# name_keys = ['individual_uuid']\n",
    "# name_keys = ['name']\n",
    "filter_key = '__'.join(name_keys)\n",
    "\n",
    "df = preprocess_data(\n",
    "    data_params['annotation_file'],\n",
    "    name_keys=name_keys,\n",
    "    convert_names_to_ids=True,\n",
    "    viewpoint_list=data_params['viewpoint_list'],\n",
    "    n_filter_min=data_params['n_filter_min'],\n",
    "    n_filter_max=data_params['n_filter_max'],\n",
    "    images_dir=data_params['images_dir'],\n",
    "    embedding_uuids=uuids\n",
    ")\n",
    "\n",
    "print_intersect_stats(df, individual_key=filter_key)\n",
    "\n",
    "# Filter dataframe by UUIDs\n",
    "filtered_df = df[df['uuid_x'].isin(uuids)]\n",
    "print('     ', len(filtered_df), 'annotations remain after filtering by the provided embeddings')\n",
    "filtered_embeddings = [embeddings[uuids.index(uuid)] for uuid in filtered_df['uuid_x']]\n",
    "print('     ', len(filtered_embeddings), 'embeddings remain after filtering by the provided annotations')\n",
    "\n",
    "# Compute statistics\n",
    "topk_results = get_stats(filtered_df, filter_key, filtered_embeddings)\n",
    "\n",
    "print(f\"Statistics: {', '.join([f'top-{k}: {100*v:.2f}%' for (k, v) in topk_results])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-03e486bbe21f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zebra_df.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"zebra_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
